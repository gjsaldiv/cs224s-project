{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6iAqK_e-z75",
    "outputId": "fa061668-4c0d-4a74-f513-71cffcf91526"
   },
   "outputs": [],
   "source": [
    "# Imports \n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.effects\n",
    "import librosa.util\n",
    "\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from transformer_models import *\n",
    "from transformer_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5IEPrjp5AtlU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 2913/7442 [08:35<14:14,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: Empty DataFrame\n",
      "Columns: [Unnamed: 0, FileName, VoiceVote, VoiceLevel, FaceVote, FaceLevel, MultiModalVote, MultiModalLevel]\n",
      "Index: []\n",
      "index count: 2912\n",
      "unable to find file: 1040_ITH_SAD_X.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7442/7442 [22:02<00:00,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data: (7442, 6)\n",
      "shape of labels: (7442,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Features we want right now: min f0, max f0, and mean f0 and maybe rms (not sure exactly what that is but was used in the paper)\n",
    "path = '/home/CREMA-D/AudioWAV/'\n",
    "files = os.listdir(path)\n",
    "\n",
    "summary = pd.read_csv('/home/CREMA-D/processedResults/summaryTable.csv')\n",
    "\n",
    "num_files = len(os.listdir(path)) #not sure how you want to count files\n",
    "count = 0\n",
    "\n",
    "# Aim to get to 12 features\n",
    "num_features = 6\n",
    "\n",
    "# Keep track of min and max duration of all data\n",
    "min_dur = np.inf\n",
    "max_dur = 0\n",
    "max_length = 0\n",
    "\n",
    "X = np.zeros((num_files, num_features))\n",
    "Y = np.zeros(num_files).astype(str)\n",
    "for sample in tqdm(files): #depends on how you access\n",
    "    file = os.path.join(path,sample)\n",
    "    current_wav, current_sr = librosa.load(file) #fix for set up \n",
    "    f0_series = librosa.yin(current_wav, librosa.note_to_hz('C2'), librosa.note_to_hz('C7'))\n",
    "    rms_series = librosa.feature.rms(y=current_wav)\n",
    "    f0_max = np.amax(f0_series)\n",
    "    f0_min = np.amin(f0_series)\n",
    "    # Get f0 range\n",
    "    f0_range = f0_max - f0_min\n",
    "    # duration\n",
    "    duration = librosa.get_duration(y=current_wav, sr=current_sr)\n",
    "    \n",
    "    # Outer duration\n",
    "    if duration > max_dur:\n",
    "        max_dur = duration\n",
    "    if duration < min_dur:\n",
    "        min_dur = duration\n",
    "        \n",
    "    # Get the pitches\n",
    "#     pitches, magnitudes = librosa.piptrack(y=current_wav, sr=current_sr)\n",
    "#     pitch_max = np.amax(pitches)\n",
    "#     pitch_min = np.amin(pitches)\n",
    "#     # Get f0 range\n",
    "#     pitch_range = pitch_max - pitch_min\n",
    "#     pitch_mean = np.mean(pitches)\n",
    "    \n",
    "    f0_mean = np.mean(f0_series)\n",
    "    rms_max = np.amax(rms_series)\n",
    "    rms_min = np.amin(rms_series)\n",
    "    rms_mean = np.mean(rms_series)\n",
    "#     x = np.array([f0_min, f0_max, f0_mean, f0_range, duration, rms_min, rms_max, rms_mean, pitch_max, pitch_min, \n",
    "#                   pitch_range, pitch_mean])\n",
    "    if num_features == 8:\n",
    "        x = np.array([f0_min, f0_max, f0_mean, f0_range, duration, rms_min, rms_max, rms_mean])\n",
    "    else:\n",
    "        x = np.array([f0_min, f0_max, f0_mean, rms_min, rms_max, rms_mean])\n",
    "    X[count,:] = x\n",
    "    # Get the label for VoiceVote\n",
    "    info = summary.loc[summary['FileName'] == sample.split('.')[0]]\n",
    "    try:\n",
    "        Y[count] = info['VoiceVote'].values[0]\n",
    "    except Exception as ex:\n",
    "        print(f'info: {info}')\n",
    "        print(f'index count: {count}')\n",
    "        index = count\n",
    "        print(f'unable to find file: {sample}')\n",
    "        count -= 1\n",
    "    count += 1\n",
    "print(f'shape of train data: {X.shape}')\n",
    "print(f'shape of labels: {Y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n60PZXht_tv-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data: (7442, 6)\n",
      "shape of labels: (7442,)\n",
      "['N' '0.0']\n",
      "New X shape: (7441, 6)\n",
      "New Y shape: (7441,)\n",
      "Example feature: [7.25388728e+01 2.79622457e+02 1.54880632e+02 4.40623751e-03\n",
      " 5.49128167e-02 1.39149548e-02]\n",
      "Last Y to check: N\n",
      "min duration: 1.2679818594104308\n",
      "max duration: 5.005034013605442\n",
      "num classes: 39\n",
      "classes: ['A' 'A:D' 'A:D:F:N' 'A:D:F:N:S' 'A:D:H:N' 'A:D:N' 'A:D:N:S' 'A:F' 'A:F:N'\n",
      " 'A:H' 'A:H:N' 'A:N' 'A:N:S' 'A:S' 'D' 'D:F' 'D:F:H:N' 'D:F:N' 'D:F:N:S'\n",
      " 'D:F:S' 'D:H' 'D:H:N' 'D:N' 'D:N:S' 'D:S' 'F' 'F:H' 'F:H:N' 'F:H:N:S'\n",
      " 'F:N' 'F:N:S' 'F:S' 'H' 'H:N' 'H:N:S' 'H:S' 'N' 'N:S' 'S']\n",
      "shape of transformed labels: (7441,)\n"
     ]
    }
   ],
   "source": [
    "#For Logistic Regression, can use sklearn.linear_model.LogisticRegression\n",
    "# !pip install -U scikit-learn\n",
    "# import sklearn\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# Remove the file that wasn't in results\n",
    "print(f'shape of train data: {X.shape}')\n",
    "print(f'shape of labels: {Y.shape}')\n",
    "print(Y[7440:])\n",
    "\n",
    "# Remove that one example without a label\n",
    "X = np.delete(X,-1,axis=0)\n",
    "Y = Y[:-1]\n",
    "print(f'New X shape: {X.shape}')\n",
    "print(f'New Y shape: {Y.shape}')\n",
    "print(f'Example feature: {X[4,:]}')\n",
    "print(f'Last Y to check: {Y[-1]}')\n",
    "print(f'min duration: {min_dur}')\n",
    "print(f'max duration: {max_dur}')\n",
    "\n",
    "# Find number of unique labels\n",
    "num_unique = np.unique(Y).shape[0]\n",
    "print(f'num classes: {num_unique}')\n",
    "\n",
    "# Use label encoder for string labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "print(f'classes: {le.classes_}')\n",
    "transformed_labels = le.transform(Y)\n",
    "print(f'shape of transformed labels: {transformed_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from the data\n",
    "class CREMADataset(Dataset):\n",
    "    \"\"\"\n",
    "    CREMA-D dataset to load and use\n",
    "    \"\"\"\n",
    "    def __init__(self, X, Y, num_examples, split='train', train_ratio = 0.8, val_ratio = 0.1):\n",
    "        super().__init__()\n",
    "        # X are the features, Y are the labels\n",
    "        self.Y = Y  \n",
    "        self.X = X\n",
    "        self.num_examples = num_examples\n",
    "        self.train_ratio = train_ratio\n",
    "        self.val_ratio = val_ratio\n",
    "\n",
    "        # Decides which indices belong to which split.\n",
    "        train_indices, val_indices, test_indices = self.split_data(num_examples, train_ratio=train_ratio, val_ratio=val_ratio)\n",
    "\n",
    "        if split == 'train':\n",
    "            indices = train_indices\n",
    "        elif split == 'val':\n",
    "            indices = val_indices\n",
    "        elif split == 'test':\n",
    "            indices = test_indices\n",
    "        else:\n",
    "            raise Exception(f'Split {split} not supported.')\n",
    "            \n",
    "        self.indices = indices\n",
    "\n",
    "    def split_data(self, num_examples, train_ratio = 0.8, val_ratio = 0.1):\n",
    "        \"\"\"Splits data into train, val, and test sets based on speaker. When \n",
    "        evaluating methods on the test split, we measure how well they generalize\n",
    "        to new (unseen) speakers.\n",
    "\n",
    "        Concretely, this stores and returns indices belonging to each split.\n",
    "        \"\"\"\n",
    "        # Fix seed so everyone reproduces the same splits.\n",
    "        rs = np.random.RandomState(42)\n",
    "\n",
    "        indices = np.arange(0, num_examples)\n",
    "        train_idx = int(num_examples * train_ratio)\n",
    "        num_remaining = num_examples - train_idx\n",
    "        val_idx = train_idx + int(num_remaining/2)\n",
    "        \n",
    "        print(f'train idx: {train_idx}')\n",
    "        print(f'val idx: {val_idx}')\n",
    "        \n",
    "        train_indices = indices[:train_idx]\n",
    "        val_indices = indices[train_idx:val_idx]\n",
    "        test_indices = indices[val_idx:]\n",
    "        return train_indices, val_indices, test_indices\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.indices[index]\n",
    "        return torch.FloatTensor(self.X[index,:]), torch.LongTensor([self.Y[index]])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns total number of utterances in the dataset.\"\"\"\n",
    "        return len(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train idx: 5952\n",
      "val idx: 6696\n",
      "train idx: 5952\n",
      "val idx: 6696\n",
      "train idx: 5952\n",
      "val idx: 6696\n",
      "5952\n",
      "744\n",
      "745\n",
      "(tensor([6.8573e+01, 2.7087e+02, 1.8743e+02, 3.4345e-03, 1.8924e-02, 8.0639e-03]), tensor([36]))\n",
      "(tensor([6.8139e+01, 7.0053e+02, 2.0496e+02, 3.7657e-03, 8.5794e-02, 2.4723e-02]), tensor([36]))\n"
     ]
    }
   ],
   "source": [
    "# Set up the dataloaders\n",
    "train_dataset = CREMADataset(X, transformed_labels, X.shape[0], split='train')\n",
    "val_dataset = CREMADataset(X, transformed_labels, X.shape[0], split='val')\n",
    "test_dataset = CREMADataset(X, transformed_labels, X.shape[0], split='test')\n",
    "\n",
    "# Check dataset length\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "# Check data\n",
    "print(train_dataset[0])\n",
    "print(test_dataset[0])\n",
    "\n",
    "# Set dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state dict\n",
    "model = EmotionTransformerPrototype(num_features, num_unique)\n",
    "model.load_state_dict(torch.load('./Results/EmotionTransformerPrototype_results/EmotionTransformerPrototype_state_dict.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.574 , Test Accuracy: 0.590, Avg F1 macro: 0.2408, Avg F1 micro: 0.596\n"
     ]
    }
   ],
   "source": [
    "# Run testing on the results\n",
    "model.eval()\n",
    "correct_test = 0\n",
    "test_loss = 0\n",
    "total_macro = 0\n",
    "total_micro = 0\n",
    "for x,y in test_loader:\n",
    "    x_cuda = x.cuda()\n",
    "    y_cuda = torch.squeeze(y).cuda()\n",
    "\n",
    "    # Output from mode\n",
    "    output = model(x_cuda)\n",
    "    output = output.cuda()\n",
    "    \n",
    "    # Loss\n",
    "    loss = criterion(output, y_cuda)\n",
    "\n",
    "    # Need to take max over the log probs (batch_size, num_classes)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    pred = pred.type(torch.FloatTensor).cuda()\n",
    "\n",
    "    num_correct = np.sum(y_cuda.cpu().detach().numpy() == pred.cpu().detach().numpy())\n",
    "    \n",
    "    f1 = f1_score(y_cuda.cpu().detach().numpy(), pred.cpu().detach().numpy(), average='macro')\n",
    "    total_macro += f1\n",
    "    f1 = f1_score(y_cuda.cpu().detach().numpy(), pred.cpu().detach().numpy(), average='micro')\n",
    "    total_micro += f1\n",
    "    \n",
    "    correct_test += num_correct\n",
    "    test_loss += loss\n",
    "# Calculate average loss\n",
    "epoch_loss = test_loss / len(test_loader)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = correct_test / (len(test_loader) * batch_size)\n",
    "avg_macro = total_macro / len(test_loader)\n",
    "avg_micro = total_micro / len(test_loader)\n",
    "print(\"Test loss: %.3f , Test Accuracy: %.3f, Avg F1 macro: %.4f, Avg F1 micro: %.3f\" % \n",
    "      (epoch_loss, accuracy, avg_macro, avg_micro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test result\n",
    "with open(path+'/test_results.txt', 'w') as f:\n",
    "    f.write(\"Test loss: %.3f , Test Accuracy: %.3f, Avg F1 macro: %.4f, Avg F1 micro: %.3f\" % \n",
    "      (epoch_loss, accuracy, avg_macro, avg_micro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JLduPvIOC7cb"
   },
   "outputs": [],
   "source": [
    "# Get data and labels for training\n",
    "# train_split = int(0.8 * num_files)\n",
    "# print('train_split: ', train_split)\n",
    "# print(f'train size: {X[:train_split].shape}, val size: {X[train_split:].shape}')\n",
    "\n",
    "# model = LogisticRegression().fit(X[:train_split], Y[:train_split])\n",
    "\n",
    "# # Predict on validation/test (80-20 split)\n",
    "# predictions = model.predict(X[train_split:])\n",
    "\n",
    "# # Output score (mean accuracy)\n",
    "# score = model.score(X[train_split:],Y[train_split:])\n",
    "# print(f'Test accuracy score: {score}')\n",
    "\n",
    "# f1 = f1_score(Y[train_split:], predictions, average='macro')\n",
    "# print(f'macro f1 score: {f1}')\n",
    "# f1 = f1_score(Y[train_split:], predictions, average='micro')\n",
    "# print(f'micro f1 score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic stats for the dataset\n",
    "# avg = np.mean(X, axis=0)\n",
    "# print(f'avg shape: {avg.shape}')\n",
    "# stats = ['f0_min', 'f0_max', 'f0_mean', 'f0_range', 'duration', 'rms_min', 'rms_max', 'rms_mean', 'pitch_max', 'pitch_min', \n",
    "#                   'pitch_range', 'pitch_mean']\n",
    "# stats = ['f0_min', 'f0_max', 'f0_mean', 'f0_range', 'duration', 'rms_min', 'rms_max', 'rms_mean']\n",
    "# for j,stat in enumerate(stats):\n",
    "#     print(f'{stat} average: {avg[j]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
