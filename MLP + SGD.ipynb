{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S6iAqK_e-z75"
   },
   "outputs": [],
   "source": [
    "# Imports \n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.effects\n",
    "import librosa.util\n",
    "\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "5IEPrjp5AtlU",
    "outputId": "31a72088-80b5-4829-b8ff-783999489e31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 5955/7442 [07:06<01:40, 14.77it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: Empty DataFrame\n",
      "Columns: [Unnamed: 0, FileName, VoiceVote, VoiceLevel, FaceVote, FaceLevel, MultiModalVote, MultiModalLevel]\n",
      "Index: []\n",
      "index count: 5952\n",
      "unable to find file: 1040_ITH_SAD_X.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7442/7442 [08:57<00:00, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data: (7442, 8)\n",
      "shape of labels: (7442,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Features we want right now: min f0, max f0, and mean f0 and maybe rms (not sure exactly what that is but was used in the paper)\n",
    "path = '/Users/gabesaldivar/Desktop/cs224s/CREMA-D/AudioWAV/'\n",
    "files = os.listdir(path)\n",
    "\n",
    "summary = pd.read_csv('/Users/gabesaldivar/Desktop/cs224s/CREMA-D/processedResults/summaryTable.csv')\n",
    "\n",
    "num_files = len(os.listdir(path)) #not sure how you want to count files\n",
    "count = 0\n",
    "# Aim to get to 12 features\n",
    "num_features = 8\n",
    "\n",
    "# Keep track of min and max duration of all data\n",
    "min_dur = np.inf\n",
    "max_dur = 0\n",
    "\n",
    "X = np.zeros((num_files, num_features))\n",
    "Y = np.zeros(num_files).astype(str)\n",
    "for sample in tqdm(files): #depends on how you access\n",
    "    file = os.path.join(path,sample)\n",
    "    current_wav, current_sr = librosa.load(file) #fix for set up \n",
    "    f0_series = librosa.yin(current_wav, librosa.note_to_hz('C2'), librosa.note_to_hz('C7'))\n",
    "    rms_series = librosa.feature.rms(y=current_wav)\n",
    "    f0_max = np.amax(f0_series)\n",
    "    f0_min = np.amin(f0_series)\n",
    "    # Get f0 range\n",
    "    f0_range = f0_max - f0_min\n",
    "    # duration\n",
    "    duration = librosa.get_duration(y=current_wav, sr=current_sr)\n",
    "    \n",
    "    # Outer duration\n",
    "    if duration > max_dur:\n",
    "        max_dur = duration\n",
    "    if duration < min_dur:\n",
    "        min_dur = duration\n",
    "        \n",
    "    # Get the pitches\n",
    "#     pitches, magnitudes = librosa.piptrack(y=current_wav, sr=current_sr)\n",
    "#     pitch_max = np.amax(pitches)\n",
    "#     pitch_min = np.amin(pitches)\n",
    "#     # Get f0 range\n",
    "#     pitch_range = pitch_max - pitch_min\n",
    "#     pitch_mean = np.mean(pitches)\n",
    "    \n",
    "    f0_mean = np.mean(f0_series)\n",
    "    rms_max = np.amax(rms_series)\n",
    "    rms_min = np.amin(rms_series)\n",
    "    rms_mean = np.mean(rms_series)\n",
    "#     x = np.array([f0_min, f0_max, f0_mean, f0_range, duration, rms_min, rms_max, rms_mean, pitch_max, pitch_min, \n",
    "#                   pitch_range, pitch_mean])\n",
    "    x = np.array([f0_min, f0_max, f0_mean, f0_range, duration, rms_min, rms_max, rms_mean])\n",
    "    X[count,:] = x\n",
    "    # Get the label for VoiceVote\n",
    "    info = summary.loc[summary['FileName'] == sample.split('.')[0]]\n",
    "    try:\n",
    "        Y[count] = info['VoiceVote'].values[0]\n",
    "    except Exception as ex:\n",
    "        print(f'info: {info}')\n",
    "        print(f'index count: {count}')\n",
    "        index = count\n",
    "        print(f'unable to find file: {sample}')\n",
    "        count -= 1\n",
    "    count += 1\n",
    "print(f'shape of train data: {X.shape}')\n",
    "print(f'shape of labels: {Y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_split:  5953\n",
      "train size: (5953, 8), val size: (1489, 8)\n",
      "Test accuracy score: 0.5245130960376091\n",
      "macro f1 score: 0.02085168869309838\n",
      "micro f1 score: 0.5245130960376091\n"
     ]
    }
   ],
   "source": [
    "# testing MLP classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "train_split = int(0.8 * num_files)\n",
    "print('train_split: ', train_split)\n",
    "print(f'train size: {X[:train_split].shape}, val size: {X[train_split:].shape}')\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "model = clf.fit(X[:train_split], Y[:train_split])\n",
    "\n",
    "# Predict on validation/test (80-20 split)\n",
    "predictions = model.predict(X[train_split:])\n",
    "\n",
    "# Output score (mean accuracy)\n",
    "score = model.score(X[train_split:],Y[train_split:])\n",
    "print(f'Test accuracy score: {score}')\n",
    "\n",
    "f1 = f1_score(Y[train_split:], predictions, average='macro')\n",
    "print(f'macro f1 score: {f1}')\n",
    "f1 = f1_score(Y[train_split:], predictions, average='micro')\n",
    "print(f'micro f1 score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_split:  5953\n",
      "train size: (5953, 8), val size: (1489, 8)\n",
      "Test accuracy score: 0.5836131631967764\n",
      "macro f1 score: 0.04133734005231342\n",
      "micro f1 score: 0.5836131631967764\n"
     ]
    }
   ],
   "source": [
    "# Testing SGD\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "train_split = int(0.8 * num_files)\n",
    "print('train_split: ', train_split)\n",
    "print(f'train size: {X[:train_split].shape}, val size: {X[train_split:].shape}')\n",
    "\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                     SGDClassifier(max_iter=1000, tol=1e-3)) \n",
    "model = clf.fit(X[:train_split], Y[:train_split])\n",
    "\n",
    "# Predict on validation/test (80-20 split)\n",
    "predictions = model.predict(X[train_split:])\n",
    "\n",
    "# Output score (mean accuracy)\n",
    "score = model.score(X[train_split:],Y[train_split:])\n",
    "print(f'Test accuracy score: {score}')\n",
    "\n",
    "f1 = f1_score(Y[train_split:], predictions, average='macro')\n",
    "print(f'macro f1 score: {f1}')\n",
    "f1 = f1_score(Y[train_split:], predictions, average='micro')\n",
    "print(f'micro f1 score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_split:  5953\n",
      "train size: (5953, 6), val size: (1489, 6)\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-79eef3910c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Output score (mean accuracy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_split\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_split\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test accuracy score: {score}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mAverage\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlikelihood\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0munder\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \"\"\"\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mscore_samples\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mXr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0mlog_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         log_like -= .5 * (n_features * log(2. * np.pi) -\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_base.py\u001b[0m in \u001b[0;36mget_precision\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_variance_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Get precision using matrix inversion lemma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0minv_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_lu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         raise ValueError('illegal value in %d-th argument of internal '\n",
      "\u001b[0;31mLinAlgError\u001b[0m: singular matrix"
     ]
    }
   ],
   "source": [
    "# testing PCA classifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "train_split = int(0.8 * num_files)\n",
    "print('train_split: ', train_split)\n",
    "print(f'train size: {X[:train_split].shape}, val size: {X[train_split:].shape}')\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "model = pca.fit(X[:train_split], Y[:train_split])\n",
    "\n",
    "# Predict on validation/test (80-20 split)\n",
    "# predictions = model.predict(X[train_split:])\n",
    "\n",
    "# Output score (mean accuracy)\n",
    "score = model.score(X[train_split:],Y[train_split:])\n",
    "print(f'Test accuracy score: {score}')\n",
    "\n",
    "f1 = f1_score(Y[train_split:], predictions, average='macro')\n",
    "print(f'macro f1 score: {f1}')\n",
    "f1 = f1_score(Y[train_split:], predictions, average='micro')\n",
    "print(f'micro f1 score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6deWxsTtsp51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0_min average: 68.42755242039749\n",
      "f0_max average: 1108.2239746103453\n",
      "f0_mean average: 197.60158873789413\n",
      "rms_min average: 0.003896712870773289\n",
      "rms_max average: 0.10690546616422825\n",
      "rms_mean average: 0.027573393515514667\n"
     ]
    }
   ],
   "source": [
    "# Some basic stats for the dataset\n",
    "avg = np.mean(X, axis=0)\n",
    "stats = ['f0_min', 'f0_max', 'f0_mean', 'rms_min', 'rms_max', 'rms_mean']\n",
    "for j,stat in enumerate(stats):\n",
    "    print(f'{stat} average: {avg[j]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS224S Final Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
